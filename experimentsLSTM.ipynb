{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments LSTM net\n",
    "\n",
    "Here we tried to replicate the network that was used in [this](https://www.nature.com/articles/s41598-018-33321-1#Sec2) paper. But instead of using GRU we used LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data_loader.data_loader import PhageLoader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_dim, sequence_length, batch_size, labset_dim=2, number_of_layers=1, bidirectional=True, device=torch.device(\"cpu\")):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_layers = number_of_layers\n",
    "        self.device = device\n",
    "        \n",
    "        hidden_dim_dense = hidden_dim\n",
    "        if bidirectional:\n",
    "            hidden_dim_dense = hidden_dim * 2\n",
    "        \n",
    "        self.kmer2embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_dim ,bidirectional=bidirectional,num_layers=number_of_layers)\n",
    "        self.dense = nn.Linear(hidden_dim_dense, labset_dim)        \n",
    "\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        # Input (shape: )\n",
    "        #print(sequence.shape)\n",
    "        #print(sequence)\n",
    "        embedded_kmers = self.kmer2embedding(sequence)\n",
    "\n",
    "        # embeddings -> LSTM hiddens (seq_len, batch, num_directions * hidden_size)\n",
    "        out_lstm, _ = self.lstm(embedded_kmers.view(self.sequence_length, self.batch_size, -1)) \n",
    "\n",
    "        # LSTM hiddens -> dense layer \n",
    "        out_dense = self.dense(out_lstm.view(-1, self.hidden_dim*2))\n",
    "\n",
    "        # dense layer -> probabilities\n",
    "        out_log = F.log_softmax(out_dense, dim = 1)\n",
    "        return out_log\n",
    "    \n",
    "    # Not being used for now\n",
    "    def initHidden(self, batch_size, hidden_size):\n",
    "        if self.bidirectional:\n",
    "            return torch.zeros(self.num_layers*2, batch_size, hidden_size, device=this.device)\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, batch_size, hidden_size, device=this.device)\n",
    "        \n",
    "    # Not being used for now\n",
    "    def create_emb_layer(self, weights_matrix, non_trainable=False):\n",
    "        num_embeddings, embedding_dim = weights_matrix.size()\n",
    "        emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "        if non_trainable:\n",
    "            emb_layer.weight.requires_grad = False\n",
    "            \n",
    "        return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up for working with GPU, if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for grid search\n",
    "window_sizes = [1] # [1, 3, 5, 7]\n",
    "strides = [1] # [1, 2]\n",
    "batch_sizes = [30] # [30, 60, 120] \n",
    "embedding_layer_sizes = [4] # [50, 100]\n",
    "hidden_layer_sizes = [30] # [30, 50, 80]\n",
    "epochs_values = [5] # [10, 50, 100]\n",
    "optimizers = ['SGD']#['SGD', 'ADAM']\n",
    "learning_rates = [0.1] # [0.1, 0.01, 0.001] \n",
    "\n",
    "# other important parameters\n",
    "#VOCAB_SIZE = len(kmers_dict)\n",
    "LABSET_DIM = 2\n",
    "BIDIRECTIONAL = True\n",
    "sequence_length = 100\n",
    "genomes_to_use = 'all' # len(loaders) for all genomes\n",
    "weights = torch.tensor([8, 1], dtype=torch.float, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "loader = PhageLoader(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 30, 4, 30, 5, 'SGD', 0.1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "hyperparams_configs = list(product(window_sizes, \\\n",
    "                                   strides, batch_sizes, \\\n",
    "                                   embedding_layer_sizes, \\\n",
    "                                   hidden_layer_sizes, \\\n",
    "                                   epochs_values, \\\n",
    "                                   optimizers, \\\n",
    "                                   learning_rates))\n",
    "hyperparams_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here just to speed up prototyping but it should be inside the loop\n",
    "#experiment_loader = loader.get_data_loader(n='all',read_length=sequence_length, batch_size=30, k=3, stride=1, embedding=\"dict\", embed_size=None, drop_last=False)\n",
    "dataset = loader.get_data_set(n_files=genomes_to_use,read_length=sequence_length, batch_size=30, k=3, stride=1, embedding=\"dict\", embed_size=None, drop_last=False)\n",
    "# n -> how many files to bring\n",
    "# read_length -> length of the sequence to read (in terms of number of k-mers)\n",
    "# batch_size -> number of rows to recieve of length \"read_length\"\n",
    "#Â k -> k-mer k\n",
    "# stride -> stride for the kmer read\n",
    "# embedding: \"dict\" to return a dictionary with the combinations of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA loading ...\n",
      "87458 69968 8745 8745\n",
      "DATA loaded\n",
      "Running experiment with (window_size = 1, stride = 1, batch_size = 30, embedding_layer_size = 4, hidden_layer_size = 30, epochs = 5, optimizer = SGD, learning_rate = 0.1)\n",
      "[1,   100] loss: 0.035\n",
      "[1,   200] loss: 0.035\n",
      "[1,   300] loss: 0.035\n",
      "[1,   400] loss: 0.035\n",
      "[1,   500] loss: 0.035\n",
      "[1,   600] loss: 0.035\n",
      "[1,   700] loss: 0.035\n",
      "[1,   800] loss: 0.035\n",
      "[1,   900] loss: 0.035\n",
      "[1,  1000] loss: 0.035\n",
      "[1,  1100] loss: 0.035\n",
      "[1,  1200] loss: 0.035\n",
      "[1,  1300] loss: 0.035\n",
      "[1,  1400] loss: 0.035\n",
      "[1,  1500] loss: 0.035\n",
      "[1,  1600] loss: 0.035\n",
      "[1,  1700] loss: 0.035\n",
      "[1,  1800] loss: 0.035\n",
      "[1,  1900] loss: 0.035\n",
      "[1,  2000] loss: 0.035\n",
      "[1,  2100] loss: 0.035\n",
      "[1,  2200] loss: 0.035\n",
      "[1,  2300] loss: 0.035\n",
      "getting accuracy\n",
      "0.8886600914808462\n",
      "getting confusion validation\n",
      "[2,   100] loss: 0.046\n",
      "[2,   200] loss: 0.035\n",
      "[2,   300] loss: 0.035\n",
      "[2,   400] loss: 0.035\n",
      "[2,   500] loss: 0.035\n",
      "[2,   600] loss: 0.035\n",
      "[2,   700] loss: 0.035\n",
      "[2,   800] loss: 0.035\n",
      "[2,   900] loss: 0.035\n",
      "[2,  1000] loss: 0.035\n",
      "[2,  1100] loss: 0.034\n",
      "[2,  1200] loss: 0.035\n",
      "[2,  1300] loss: 0.035\n",
      "[2,  1400] loss: 0.035\n",
      "[2,  1500] loss: 0.035\n",
      "[2,  1600] loss: 0.035\n",
      "[2,  1700] loss: 0.035\n",
      "[2,  1800] loss: 0.035\n",
      "[2,  1900] loss: 0.035\n",
      "[2,  2000] loss: 0.035\n",
      "[2,  2100] loss: 0.035\n",
      "[2,  2200] loss: 0.035\n",
      "[2,  2300] loss: 0.035\n",
      "getting accuracy\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "# Set up the experiment \n",
    "\n",
    "print('DATA loading ...')\n",
    "dataset = loader.get_data_set(n_files=genomes_to_use,read_length=sequence_length, batch_size=1, k=window_sizes[0], stride=1, embedding=\"dict\", embed_size=None, drop_last=False)\n",
    "train_sampler, valid_sampler, test_sampler = split_sets(dataset)\n",
    "print('DATA loaded')\n",
    "\n",
    "for (window_size, stride, batch_size, embedding_layer_size, hidden_layer_size, epochs, optimizer_name, learning_rate) in hyperparams_configs:\n",
    "    \n",
    "    print('Running experiment with (window_size = %s, stride = %s, batch_size = %s, embedding_layer_size = %s, hidden_layer_size = %s, epochs = %s, optimizer = %s, learning_rate = %s)' % (window_size, stride, batch_size, embedding_layer_size, hidden_layer_size, epochs, optimizer_name, learning_rate))\n",
    "    \n",
    "    train = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler,drop_last=True)\n",
    "    validation = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                        sampler=valid_sampler,drop_last=True)\n",
    "    test = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                        sampler=test_sampler,drop_last=True)\n",
    "    \n",
    "    VOCAB_SIZE = 4**window_size\n",
    "    \n",
    "    basicLSTM = BasicLSTM(vocab_size = VOCAB_SIZE, \\\n",
    "              embedding_size = embedding_layer_size, \\\n",
    "              hidden_dim = hidden_layer_size,\\\n",
    "            sequence_length = 100, \\\n",
    "            batch_size = batch_size, \\\n",
    "              labset_dim= LABSET_DIM,\\\n",
    "              number_of_layers = 1, \\\n",
    "              bidirectional=BIDIRECTIONAL, \\\n",
    "              device=device)\n",
    "    \n",
    "    basicLSTM.to(device) # will move to cuda if available\n",
    "    loss_function = nn.NLLLoss(weight=weights)\n",
    "    optimizer = optim.SGD(basicLSTM.parameters(), lr=learning_rate)\n",
    "    if optimizer_name == 'ADAM':\n",
    "        pass # use ADAM\n",
    "\n",
    "    # For the reports\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    tn = [] \n",
    "    fp = [] \n",
    "    fn = [] \n",
    "    tp = []\n",
    "    e_running_loss = [] \n",
    "    dataset_type = [] \n",
    "    epochs_ids = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "            # Iterate over all the training set\n",
    "            for b, (x, y) in enumerate(train):\n",
    "\n",
    "                basicLSTM.zero_grad()                    \n",
    "                x = x.type(torch.LongTensor)\n",
    "                y = y.type(torch.LongTensor)\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                if y.size()[0] != batch_size:\n",
    "                    break\n",
    "\n",
    "                out = basicLSTM(x)  \n",
    "                y = y.view(batch_size*sequence_length)\n",
    "                out = out.view(batch_size*sequence_length,2)\n",
    "                loss = loss_function(out, y)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if b % 100 == 99:\n",
    "                #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                    #check_gradients(basicLSTM)\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, b + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0\n",
    "        \n",
    "            # Compute metrics for each epoch\n",
    "\n",
    "#             print(\"appending values\")\n",
    "            \n",
    "            epochs_ids.append(epoch); epochs_ids.append(epoch);\n",
    "            e_running_loss.append(running_loss); e_running_loss.append(running_loss);\n",
    "\n",
    "            nb_classes = 2\n",
    "            \n",
    "            print('getting accuracy')\n",
    "            print(accuracy_test(train,basicLSTM, batch_size, read_length=sequence_length, output_labels=2))\n",
    "\n",
    "            # Metrics on training set\n",
    "#             print('getting confusion train')\n",
    "#             tn_e, fp_e, fn_e, tp_e = get_confusion_matrix(basicLSTM, train)\n",
    "#             tn.append(tn_e); fp.append(fp_e); fn.append(fn_e); tp.append(tp_e);\n",
    "#             dataset_type.append('train')\n",
    "            \n",
    "            # Metrics on validation set\n",
    "            print('getting confusion validation')\n",
    "            tn_e, fp_e, fn_e, tp_e = get_confusion_matrix(basicLSTM, validation, device)\n",
    "            tn.append(tn_e); fp.append(fp_e); fn.append(fn_e); tp.append(tp_e);\n",
    "            dataset_type.append('validation')\n",
    "            \n",
    "            \n",
    "    experiment_report = pd.DataFrame({'epoch': epochs_ids,\\\n",
    "                                     'running_loss': e_running_loss,\\\n",
    "                                     'dataset_type': dataset_type,\\\n",
    "                                     'tn': tn,\\\n",
    "                                     'fp': fp,\\\n",
    "                                     'fn': fn,\\\n",
    "                                     'tp': tp})\n",
    "    experiment_report['accuracy'] = experiment_report.apply(lambda row: (row.tp + row.tn)/(row.tp + row.tn + row.fp + row.fn),axis=1)\n",
    "    report_file_name = '%s-%s-%s-%s-%s-%s-%s-%s-%s' % (sequence_length, window_size, stride, batch_size, embedding_layer_size, hidden_layer_size, epochs, optimizer_name, learning_rate)\n",
    "    experiment_report.to_csv('experiments_reports/%s.csv' % report_file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>running_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.044041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22.043670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22.015196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22.113763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22.213972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>22.125531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>22.202421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>22.243479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>22.147762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>22.210295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>22.172639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>22.200302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>22.311187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>21.980005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>22.089776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>22.137400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>22.236135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>22.113373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>22.046386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>22.074834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>22.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>22.187958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>21.875294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>22.117229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>22.097690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>22.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>22.227066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>22.191136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>22.208110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>22.225445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>22.104776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>22.261937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>22.179348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>22.123414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>22.121528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>22.154198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>22.195959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>22.137714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>22.252675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>22.101770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  running_loss\n",
       "0       0     22.044041\n",
       "1       1     22.043670\n",
       "2       2     22.015196\n",
       "3       3     22.113763\n",
       "4       4     22.213972\n",
       "5       5     22.125531\n",
       "6       6     22.202421\n",
       "7       7     22.243479\n",
       "8       8     22.147762\n",
       "9       9     22.210295\n",
       "10     10     22.172639\n",
       "11     11     22.200302\n",
       "12     12     22.311187\n",
       "13     13     21.980005\n",
       "14     14     22.089776\n",
       "15     15     22.137400\n",
       "16     16     22.236135\n",
       "17     17     22.113373\n",
       "18     18     22.046386\n",
       "19     19     22.074834\n",
       "20     20     22.000103\n",
       "21     21     22.187958\n",
       "22     22     21.875294\n",
       "23     23     22.117229\n",
       "24     24     22.097690\n",
       "25     25     22.207700\n",
       "26     26     22.227066\n",
       "27     27     22.191136\n",
       "28     28     22.208110\n",
       "29     29     22.225445\n",
       "30     30     22.104776\n",
       "31     31     22.261937\n",
       "32     32     22.179348\n",
       "33     33     22.123414\n",
       "34     34     22.121528\n",
       "35     35     22.154198\n",
       "36     36     22.195959\n",
       "37     37     22.137714\n",
       "38     38     22.252675\n",
       "39     39     22.101770"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_report = pd.DataFrame({'epoch': epochs_ids[0:79:2],\\\n",
    "                                     'running_loss': e_running_loss[0:79:2]})#,\\\n",
    "#                                      'dataset_type': dataset_type[0:39]}),\\\n",
    "                                     #'tn': tn[0:39],\\\n",
    "                                     #'fp': fp[0:39],\\\n",
    "                                     #'fn': fn[0:39],\\\n",
    "                                     #'tp': tp[0:39]})\n",
    "experiment_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took 25 minutes with 10 genomes and 10 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a56f30896f80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#experiment_report['accuracy'] = experiment_report.apply(lambda row: (row.tp + row.tn)/(row.tp + row.tn + row.fp + row.fn),axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexperiment_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment_report' is not defined"
     ]
    }
   ],
   "source": [
    "#experiment_report['accuracy'] = experiment_report.apply(lambda row: (row.tp + row.tn)/(row.tp + row.tn + row.fp + row.fn),axis=1)\n",
    "experiment_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23002"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trainable parameters of pytorch model\n",
    "#pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params = sum(p.numel() for p in basicLSTM.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>epoch</th>\n",
       "      <th>running_loss</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.519275</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41366.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372634.0</td>\n",
       "      <td>0.900082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.669087</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319561.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010439.0</td>\n",
       "      <td>0.904036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.669087</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372698.0</td>\n",
       "      <td>0.900237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.922885</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319311.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010689.0</td>\n",
       "      <td>0.904111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.922885</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372666.0</td>\n",
       "      <td>0.900159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.315944</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010769.0</td>\n",
       "      <td>0.904135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.315944</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41463.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372537.0</td>\n",
       "      <td>0.899848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.908446</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319310.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010690.0</td>\n",
       "      <td>0.904111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2.908446</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372762.0</td>\n",
       "      <td>0.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3.245410</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010666.0</td>\n",
       "      <td>0.904104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3.245410</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41346.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372654.0</td>\n",
       "      <td>0.900130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3.170949</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010550.0</td>\n",
       "      <td>0.904069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3.170949</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372702.0</td>\n",
       "      <td>0.900246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3.504604</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319489.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010511.0</td>\n",
       "      <td>0.904057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3.504604</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41373.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372627.0</td>\n",
       "      <td>0.900065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  epoch  running_loss dataset_type   tn        fp   fn  \\\n",
       "0            0      0      2.519275   validation  0.0   41366.0  0.0   \n",
       "1            1      1      3.669087        train  0.0  319561.0  0.0   \n",
       "2            2      1      3.669087   validation  0.0   41302.0  0.0   \n",
       "3            3      2      2.922885        train  0.0  319311.0  0.0   \n",
       "4            4      2      2.922885   validation  0.0   41334.0  0.0   \n",
       "5            5      3      3.315944        train  0.0  319231.0  0.0   \n",
       "6            6      3      3.315944   validation  0.0   41463.0  0.0   \n",
       "7            7      4      2.908446        train  0.0  319310.0  0.0   \n",
       "8            8      4      2.908446   validation  0.0   41238.0  0.0   \n",
       "9            9      5      3.245410        train  0.0  319334.0  0.0   \n",
       "10          10      5      3.245410   validation  0.0   41346.0  0.0   \n",
       "11          11      6      3.170949        train  0.0  319450.0  0.0   \n",
       "12          12      6      3.170949   validation  0.0   41298.0  0.0   \n",
       "13          13      7      3.504604        train  0.0  319489.0  0.0   \n",
       "14          14      7      3.504604   validation  0.0   41373.0  0.0   \n",
       "\n",
       "           tp  accuracy  \n",
       "0    372634.0  0.900082  \n",
       "1   3010439.0  0.904036  \n",
       "2    372698.0  0.900237  \n",
       "3   3010689.0  0.904111  \n",
       "4    372666.0  0.900159  \n",
       "5   3010769.0  0.904135  \n",
       "6    372537.0  0.899848  \n",
       "7   3010690.0  0.904111  \n",
       "8    372762.0  0.900391  \n",
       "9   3010666.0  0.904104  \n",
       "10   372654.0  0.900130  \n",
       "11  3010550.0  0.904069  \n",
       "12   372702.0  0.900246  \n",
       "13  3010511.0  0.904057  \n",
       "14   372627.0  0.900065  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_report = pd.read_csv('experiments_reports/100-3-1-30-50-30-10-SGD-0.1.csv')\n",
    "experiment_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f19e264a5f8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#losses\n",
    "plt.figure(figsize=(13,5))\n",
    "#sns.lineplot(x=range(len(losses)),y=losses)\n",
    "# sns.lineplot(x=experiment_report[experiment_report.dataset_type=='train'].epoch.values, y=experiment_report[experiment_report.dataset_type=='train'].running_loss.values)\n",
    "sns.lineplot(x=experiment_report.epoch.values, y=experiment_report.running_loss.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of inter-genic : 100 %\n",
      "Accuracy of genic :  0 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "classes = {0: 'inter-genic', 1: 'genic'}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (raw_kmer, raw_labels) in enumerate(test):\n",
    "        kmer = prepareSequence(raw_kmer, kmers_dict)\n",
    "        labels = torch.tensor(raw_labels)\n",
    "        out = basicLSTM(labels)\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(1):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "squeeze(dim=None) -> Tensor\n",
       "\n",
       "See :func:`torch.squeeze`\n",
       "\u001b[0;31mType:\u001b[0m      method_descriptor\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.Tensor.squeeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a sampler for each set of the design set\n",
    "def split_sets(dataset):\n",
    "    n = len(dataset)  # how many total elements you have\n",
    "    test_size = .1\n",
    "    n_test = int( n * test_size )  # number of test/val elements\n",
    "    n_train = n - 2 * n_test\n",
    "\n",
    "    idx = list(range(n))  # indices to all elements\n",
    "    np.random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
    "    train_idx = idx[:n_train]\n",
    "    val_idx = idx[n_train:(n_train + n_test)]\n",
    "    test_idx = idx[(n_train + n_test):]\n",
    "\n",
    "    print(n,len(train_idx),len(val_idx),len(test_idx))\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(val_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    return train_sampler, valid_sampler, test_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e03a603cee7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train, validation, test = split_sets(dataset, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[y0 and pred0 (), y0 and pred1 ()]\n",
    "# [y1 and pred0 (), y1 and pred1 (TP)]]]\n",
    "def get_confusion_matrix(model, dataset, device):\n",
    "    y_lists = []\n",
    "    preds_lists = []\n",
    "    confusion_matrix_manual = torch.zeros(2, 2)\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(dataset):\n",
    "            x = x.type(torch.LongTensor)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            _, preds = torch.max(out, 1)\n",
    "            #y_lists.append(y.view(-1).cpu().numpy())\n",
    "            #preds_lists.append(preds.view(-1).cpu().numpy())\n",
    "            for t, p in zip(y.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix_manual[t.long(), p.long()] += 1\n",
    "\n",
    "#     To compare with numpy\n",
    "#     y_array = np.concatenate(y_lists)\n",
    "#     preds_array = np.concatenate(preds_lists)\n",
    "#     print(preds_array.shape)\n",
    "#     print(preds_array)\n",
    "#     sk_confusion = confusion_matrix(y_array, preds_array)\n",
    "\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix_manual.numpy().ravel()\n",
    "    \n",
    "    return (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(loader,model, batch_size, read_length, output_labels=2):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        for b, (x, y) in enumerate(loader):\n",
    "            x = x.type(torch.LongTensor)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            y = y.view(batch_size*read_length)\n",
    "            out = out.view(batch_size*read_length,output_labels).exp()\n",
    "            _, out_index= torch.max(out,dim=-1)\n",
    "            #print(out_index)\n",
    "            correct += (out_index.eq(y)).sum()\n",
    "            total += len(y)\n",
    "    return correct.item()/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradients(model):\n",
    "    lstm = model.lstm\n",
    "    for p,n in zip(lstm.parameters(),lstm._all_weights[0]):\n",
    "        if n[:6] == 'weight':\n",
    "            print('===========\\ngradient:{}\\n----------\\n{}'.format(n,p.grad.abs().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
