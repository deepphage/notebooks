{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments LSTM net\n",
    "\n",
    "Here we tried to replicate the network that was used in [this](https://www.nature.com/articles/s41598-018-33321-1#Sec2) paper. But instead of using GRU we used LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data_loader.data_loader import PhageLoader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_dim, sequence_length, batch_size, labset_dim=2, number_of_layers=1, bidirectional=True, device=torch.device(\"cpu\")):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_layers = number_of_layers\n",
    "        self.device = device\n",
    "        \n",
    "        hidden_dim_dense = hidden_dim\n",
    "        if bidirectional:\n",
    "            hidden_dim_dense = hidden_dim * 2\n",
    "        \n",
    "        self.kmer2embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_dim ,bidirectional=bidirectional,num_layers=number_of_layers)\n",
    "        self.dense = nn.Linear(hidden_dim_dense, labset_dim)        \n",
    "\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        # Input (shape: )\n",
    "        #print(sequence.shape)\n",
    "        #print(sequence)\n",
    "        embedded_kmers = self.kmer2embedding(sequence)\n",
    "\n",
    "        # embeddings -> LSTM hiddens (seq_len, batch, num_directions * hidden_size)\n",
    "        out_lstm, _ = self.lstm(embedded_kmers.view(self.sequence_length, self.batch_size, -1)) \n",
    "\n",
    "        # LSTM hiddens -> dense layer \n",
    "        out_dense = self.dense(out_lstm.view(-1, self.hidden_dim*2))\n",
    "\n",
    "        # dense layer -> probabilities\n",
    "        out_log = F.log_softmax(out_dense, dim = 1)\n",
    "        return out_log\n",
    "    \n",
    "    # Not being used for now\n",
    "    def initHidden(self, batch_size, hidden_size):\n",
    "        if self.bidirectional:\n",
    "            return torch.zeros(self.num_layers*2, batch_size, hidden_size, device=this.device)\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, batch_size, hidden_size, device=this.device)\n",
    "        \n",
    "    # Not being used for now\n",
    "    def create_emb_layer(self, weights_matrix, non_trainable=False):\n",
    "        num_embeddings, embedding_dim = weights_matrix.size()\n",
    "        emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "        if non_trainable:\n",
    "            emb_layer.weight.requires_grad = False\n",
    "            \n",
    "        return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up for working with GPU, if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for grid search\n",
    "window_sizes = [1] # [1, 3, 5, 7]\n",
    "strides = [1] # [1, 2]\n",
    "batch_sizes = [30] # [30, 60, 120] \n",
    "embedding_layer_sizes = [4] # [50, 100]\n",
    "hidden_layer_sizes = [30] # [30, 50, 80]\n",
    "epochs_values = [15] # [10, 50, 100]\n",
    "optimizers = ['SGD']#['SGD', 'ADAM']\n",
    "learning_rates = [0.1] # [0.1, 0.01, 0.001] \n",
    "\n",
    "# other important parameters\n",
    "#VOCAB_SIZE = len(kmers_dict)\n",
    "LABSET_DIM = 2\n",
    "BIDIRECTIONAL = True\n",
    "sequence_length = 100\n",
    "genomes_to_use = 'all' # len(loaders) for all genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "loader = PhageLoader(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 30, 4, 30, 15, 'SGD', 0.1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "hyperparams_configs = list(product(window_sizes, \\\n",
    "                                   strides, batch_sizes, \\\n",
    "                                   embedding_layer_sizes, \\\n",
    "                                   hidden_layer_sizes, \\\n",
    "                                   epochs_values, \\\n",
    "                                   optimizers, \\\n",
    "                                   learning_rates))\n",
    "hyperparams_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here just to speed up prototyping but it should be inside the loop\n",
    "#experiment_loader = loader.get_data_loader(n='all',read_length=sequence_length, batch_size=30, k=3, stride=1, embedding=\"dict\", embed_size=None, drop_last=False)\n",
    "dataset = loader.get_data_set(n_files=genomes_to_use,read_length=sequence_length, batch_size=30, k=3, stride=1, embedding=\"dict\", embed_size=None, drop_last=False)\n",
    "# n -> how many files to bring\n",
    "# read_length -> length of the sequence to read (in terms of number of k-mers)\n",
    "# batch_size -> number of rows to recieve of length \"read_length\"\n",
    "#Â k -> k-mer k\n",
    "# stride -> stride for the kmer read\n",
    "# embedding: \"dict\" to return a dictionary with the combinations of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA loading ...\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "# Set up the experiment \n",
    "\n",
    "print('DATA loading ...')\n",
    "dataset = loader.get_data_set(n_files=genomes_to_use,read_length=sequence_length, batch_size=1, k=window_sizes[0], stride=1, embedding=\"dict\", embed_size=None, drop_last=False)\n",
    "train_sampler, valid_sampler, test_sampler = split_sets(dataset)\n",
    "print('DATA loaded')\n",
    "\n",
    "for (window_size, stride, batch_size, embedding_layer_size, hidden_layer_size, epochs, optimizer_name, learning_rate) in hyperparams_configs:\n",
    "    \n",
    "    print('Running experiment with (window_size = %s, stride = %s, batch_size = %s, embedding_layer_size = %s, hidden_layer_size = %s, epochs = %s, optimizer = %s, learning_rate = %s)' % (window_size, stride, batch_size, embedding_layer_size, hidden_layer_size, epochs, optimizer_name, learning_rate))\n",
    "    \n",
    "    train = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler,drop_last=True)\n",
    "    validation = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                        sampler=valid_sampler,drop_last=True)\n",
    "    test = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                        sampler=test_sampler,drop_last=True)\n",
    "    \n",
    "    VOCAB_SIZE = 4**window_size\n",
    "    \n",
    "    basicLSTM = BasicLSTM(vocab_size = VOCAB_SIZE, \\\n",
    "              embedding_size = embedding_layer_size, \\\n",
    "              hidden_dim = hidden_layer_size,\\\n",
    "            sequence_length = 100, \\\n",
    "            batch_size = batch_size, \\\n",
    "              labset_dim= LABSET_DIM,\\\n",
    "              number_of_layers = 1, \\\n",
    "              bidirectional=BIDIRECTIONAL, \\\n",
    "              device=device)\n",
    "    \n",
    "    basicLSTM.to(device) # will move to cuda if available\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(basicLSTM.parameters(), lr=learning_rate)\n",
    "    if optimizer_name == 'ADAM':\n",
    "        pass # use ADAM\n",
    "\n",
    "    # For the reports\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    tn = [] \n",
    "    fp = [] \n",
    "    fn = [] \n",
    "    tp = []\n",
    "    e_running_loss = [] \n",
    "    dataset_type = [] \n",
    "    epochs_ids = []\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "            # Iterate over all the training set\n",
    "            for b, (x, y) in enumerate(train):\n",
    "\n",
    "                basicLSTM.zero_grad()                    \n",
    "                x = x.type(torch.LongTensor)\n",
    "                y = y.type(torch.LongTensor)\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                if y.size()[0] != batch_size:\n",
    "                    break\n",
    "\n",
    "                out = basicLSTM(x)  \n",
    "                y = y.view(batch_size*sequence_length)\n",
    "                out = out.view(batch_size*sequence_length,2)\n",
    "                loss = loss_function(out, y)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if b % 100 == 99:\n",
    "                #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                    #check_gradients(basicLSTM)\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, b + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0\n",
    "        \n",
    "            # Compute metrics for each epoch\n",
    "\n",
    "            epochs_ids.append(epoch); epochs_ids.append(epoch);\n",
    "            e_running_loss.append(running_loss); e_running_loss.append(running_loss);\n",
    "\n",
    "            nb_classes = 2\n",
    "\n",
    "            # Metrics on training set\n",
    "            tn_e, fp_e, fn_e, tp_e = get_confusion_matrix(basicLSTM, train)\n",
    "            tn.append(tn_e); fp.append(fp_e); fn.append(fn_e); tp.append(tp_e);\n",
    "            dataset_type.append('train')\n",
    "            \n",
    "            # Metrics on validation set\n",
    "            tn_e, fp_e, fn_e, tp_e = get_confusion_matrix(basicLSTM, validation)\n",
    "            tn.append(tn_e); fp.append(fp_e); fn.append(fn_e); tp.append(tp_e);\n",
    "            dataset_type.append('validation')\n",
    "            \n",
    "    experiment_report = pd.DataFrame({'epoch': epochs_ids,\\\n",
    "                                     'running_loss': e_running_loss,\\\n",
    "                                     'dataset_type': dataset_type,\\\n",
    "                                     'tn': tn,\\\n",
    "                                     'fp': fp,\\\n",
    "                                     'fn': fn,\\\n",
    "                                     'tp': tp})\n",
    "    experiment_report['accuracy'] = experiment_report.apply(lambda row: (row.tp + row.tn)/(row.tp + row.tn + row.fp + row.fn),axis=1)\n",
    "    report_file_name = '%s-%s-%s-%s-%s-%s-%s-%s-%s' % (sequence_length, window_size, stride, batch_size, embedding_layer_size, hidden_layer_size, epochs, optimizer_name, learning_rate)\n",
    "    experiment_report.to_csv('experiments_reports/%s.csv' % report_file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_report = pd.DataFrame({'epoch': epochs_ids[1:16],\\\n",
    "                                     'running_loss': e_running_loss[1:16],\\\n",
    "                                     'dataset_type': dataset_type[1:16],\\\n",
    "                                     'tn': tn[1:16],\\\n",
    "                                     'fp': fp[1:16],\\\n",
    "                                     'fn': fn[1:16],\\\n",
    "                                     'tp': tp[1:16]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took 25 minutes with 10 genomes and 10 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>running_loss</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.519275</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41366.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372634.0</td>\n",
       "      <td>0.900082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.669087</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319561.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010439.0</td>\n",
       "      <td>0.904036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.669087</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372698.0</td>\n",
       "      <td>0.900237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2.922885</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319311.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010689.0</td>\n",
       "      <td>0.904111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.922885</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372666.0</td>\n",
       "      <td>0.900159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3.315944</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010769.0</td>\n",
       "      <td>0.904135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3.315944</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41463.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372537.0</td>\n",
       "      <td>0.899848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2.908446</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319310.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010690.0</td>\n",
       "      <td>0.904111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2.908446</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372762.0</td>\n",
       "      <td>0.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>3.245410</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010666.0</td>\n",
       "      <td>0.904104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3.245410</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41346.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372654.0</td>\n",
       "      <td>0.900130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>3.170949</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010550.0</td>\n",
       "      <td>0.904069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>3.170949</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372702.0</td>\n",
       "      <td>0.900246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>3.504604</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319489.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010511.0</td>\n",
       "      <td>0.904057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>3.504604</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41373.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372627.0</td>\n",
       "      <td>0.900065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  running_loss dataset_type   tn        fp   fn         tp  accuracy\n",
       "0       0      2.519275   validation  0.0   41366.0  0.0   372634.0  0.900082\n",
       "1       1      3.669087        train  0.0  319561.0  0.0  3010439.0  0.904036\n",
       "2       1      3.669087   validation  0.0   41302.0  0.0   372698.0  0.900237\n",
       "3       2      2.922885        train  0.0  319311.0  0.0  3010689.0  0.904111\n",
       "4       2      2.922885   validation  0.0   41334.0  0.0   372666.0  0.900159\n",
       "5       3      3.315944        train  0.0  319231.0  0.0  3010769.0  0.904135\n",
       "6       3      3.315944   validation  0.0   41463.0  0.0   372537.0  0.899848\n",
       "7       4      2.908446        train  0.0  319310.0  0.0  3010690.0  0.904111\n",
       "8       4      2.908446   validation  0.0   41238.0  0.0   372762.0  0.900391\n",
       "9       5      3.245410        train  0.0  319334.0  0.0  3010666.0  0.904104\n",
       "10      5      3.245410   validation  0.0   41346.0  0.0   372654.0  0.900130\n",
       "11      6      3.170949        train  0.0  319450.0  0.0  3010550.0  0.904069\n",
       "12      6      3.170949   validation  0.0   41298.0  0.0   372702.0  0.900246\n",
       "13      7      3.504604        train  0.0  319489.0  0.0  3010511.0  0.904057\n",
       "14      7      3.504604   validation  0.0   41373.0  0.0   372627.0  0.900065"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_report['accuracy'] = experiment_report.apply(lambda row: (row.tp + row.tn)/(row.tp + row.tn + row.fp + row.fn),axis=1)\n",
    "experiment_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23002"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trainable parameters of pytorch model\n",
    "#pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params = sum(p.numel() for p in basicLSTM.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>epoch</th>\n",
       "      <th>running_loss</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.519275</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41366.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372634.0</td>\n",
       "      <td>0.900082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.669087</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319561.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010439.0</td>\n",
       "      <td>0.904036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.669087</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372698.0</td>\n",
       "      <td>0.900237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.922885</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319311.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010689.0</td>\n",
       "      <td>0.904111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.922885</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372666.0</td>\n",
       "      <td>0.900159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.315944</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010769.0</td>\n",
       "      <td>0.904135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.315944</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41463.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372537.0</td>\n",
       "      <td>0.899848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.908446</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319310.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010690.0</td>\n",
       "      <td>0.904111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2.908446</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372762.0</td>\n",
       "      <td>0.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3.245410</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010666.0</td>\n",
       "      <td>0.904104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3.245410</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41346.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372654.0</td>\n",
       "      <td>0.900130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3.170949</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010550.0</td>\n",
       "      <td>0.904069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3.170949</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372702.0</td>\n",
       "      <td>0.900246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3.504604</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319489.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3010511.0</td>\n",
       "      <td>0.904057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3.504604</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41373.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372627.0</td>\n",
       "      <td>0.900065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  epoch  running_loss dataset_type   tn        fp   fn  \\\n",
       "0            0      0      2.519275   validation  0.0   41366.0  0.0   \n",
       "1            1      1      3.669087        train  0.0  319561.0  0.0   \n",
       "2            2      1      3.669087   validation  0.0   41302.0  0.0   \n",
       "3            3      2      2.922885        train  0.0  319311.0  0.0   \n",
       "4            4      2      2.922885   validation  0.0   41334.0  0.0   \n",
       "5            5      3      3.315944        train  0.0  319231.0  0.0   \n",
       "6            6      3      3.315944   validation  0.0   41463.0  0.0   \n",
       "7            7      4      2.908446        train  0.0  319310.0  0.0   \n",
       "8            8      4      2.908446   validation  0.0   41238.0  0.0   \n",
       "9            9      5      3.245410        train  0.0  319334.0  0.0   \n",
       "10          10      5      3.245410   validation  0.0   41346.0  0.0   \n",
       "11          11      6      3.170949        train  0.0  319450.0  0.0   \n",
       "12          12      6      3.170949   validation  0.0   41298.0  0.0   \n",
       "13          13      7      3.504604        train  0.0  319489.0  0.0   \n",
       "14          14      7      3.504604   validation  0.0   41373.0  0.0   \n",
       "\n",
       "           tp  accuracy  \n",
       "0    372634.0  0.900082  \n",
       "1   3010439.0  0.904036  \n",
       "2    372698.0  0.900237  \n",
       "3   3010689.0  0.904111  \n",
       "4    372666.0  0.900159  \n",
       "5   3010769.0  0.904135  \n",
       "6    372537.0  0.899848  \n",
       "7   3010690.0  0.904111  \n",
       "8    372762.0  0.900391  \n",
       "9   3010666.0  0.904104  \n",
       "10   372654.0  0.900130  \n",
       "11  3010550.0  0.904069  \n",
       "12   372702.0  0.900246  \n",
       "13  3010511.0  0.904057  \n",
       "14   372627.0  0.900065  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_report = pd.read_csv('experiments_reports/100-3-1-30-50-30-10-SGD-0.1.csv')\n",
    "experiment_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2aeba898>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#losses\n",
    "plt.figure(figsize=(13,5))\n",
    "#sns.lineplot(x=range(len(losses)),y=losses)\n",
    "sns.lineplot(x=experiment_report[experiment_report.dataset_type=='train'].epoch.values, y=experiment_report[experiment_report.dataset_type=='train'].running_loss.values)\n",
    "# experiment_report.running_loss.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of inter-genic : 100 %\n",
      "Accuracy of genic :  0 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "classes = {0: 'inter-genic', 1: 'genic'}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (raw_kmer, raw_labels) in enumerate(test):\n",
    "        kmer = prepareSequence(raw_kmer, kmers_dict)\n",
    "        labels = torch.tensor(raw_labels)\n",
    "        out = basicLSTM(labels)\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(1):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "squeeze(dim=None) -> Tensor\n",
       "\n",
       "See :func:`torch.squeeze`\n",
       "\u001b[0;31mType:\u001b[0m      method_descriptor\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.Tensor.squeeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a sampler for each set of the design set\n",
    "def split_sets(dataset):\n",
    "    n = len(dataset)  # how many total elements you have\n",
    "    test_size = .1\n",
    "    n_test = int( n * test_size )  # number of test/val elements\n",
    "    n_train = n - 2 * n_test\n",
    "\n",
    "    idx = list(range(n))  # indices to all elements\n",
    "    np.random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
    "    train_idx = idx[:n_train]\n",
    "    val_idx = idx[n_train:(n_train + n_test)]\n",
    "    test_idx = idx[(n_train + n_test):]\n",
    "\n",
    "    print(n,len(train_idx),len(val_idx),len(test_idx))\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(val_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    return train_sampler, valid_sampler, test_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e03a603cee7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train, validation, test = split_sets(dataset, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[y0 and pred0 (), y0 and pred1 ()]\n",
    "# [y1 and pred0 (), y1 and pred1 (TP)]]]\n",
    "def get_confusion_matrix(model, dataset):\n",
    "    y_lists = []\n",
    "    preds_lists = []\n",
    "    confusion_matrix_manual = torch.zeros(2, 2)\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(dataset):\n",
    "            x = x.type(torch.LongTensor)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            _, preds = torch.max(out, 1)\n",
    "            y_lists.append(y.view(-1).numpy())\n",
    "            preds_lists.append(preds.view(-1).numpy())\n",
    "            for t, p in zip(y.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix_manual[t.long(), p.long()] += 1\n",
    "\n",
    "#     To compare with numpy\n",
    "#     y_array = np.concatenate(y_lists)\n",
    "#     preds_array = np.concatenate(preds_lists)\n",
    "#     print(preds_array.shape)\n",
    "#     print(preds_array)\n",
    "#     sk_confusion = confusion_matrix(y_array, preds_array)\n",
    "\n",
    "    \n",
    "    tn, fp, fn, tp= confusion_matrix_manual.numpy().ravel()\n",
    "    \n",
    "    return (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradients(model):\n",
    "    lstm = model.lstm\n",
    "    for p,n in zip(lstm.parameters(),lstm._all_weights[0]):\n",
    "        if n[:6] == 'weight':\n",
    "            print('===========\\ngradient:{}\\n----------\\n{}'.format(n,p.grad.abs().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
